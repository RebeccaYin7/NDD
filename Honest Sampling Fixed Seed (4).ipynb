{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "import pickle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree._classes import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "\n",
    "from hyppo.tools import multimodal_independence, indep_sim\n",
    "from hyppo.ksample._utils import k_sample_transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stat_helper(est_nodes, eval_nodes, est_classes, class_counts, K, kappa=3, base=2):\n",
    "    \"\"\"\n",
    "    est_nodes : list\n",
    "        Leaf indices used for voting\n",
    "    eval_nodes : list\n",
    "        Leaf indices in which a sample from the density subsample falls\n",
    "    est_classes : list\n",
    "        Voter class labels in est_node leaves\n",
    "    \"\"\"\n",
    "    for i in range(len(est_nodes)):\n",
    "        class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "\n",
    "    # Total number of estimation points in each leaf.\n",
    "    row_sums = class_counts.sum(axis=1)\n",
    "    row_sums[row_sums == 0] = 1  # Avoid divide by zero.\n",
    "    class_probs = class_counts / row_sums[:, None]\n",
    "\n",
    "    # Make the nodes that have no estimation indices uniform.\n",
    "    # This includes non-leaf nodes, but tha t will not affect the estimate.\n",
    "    class_probs[np.argwhere(class_probs.sum(axis=1) == 0)] = [1 / K]*K\n",
    "    # Apply finite sample correction and renormalize.\n",
    "    where_0 = np.argwhere(class_probs == 0)\n",
    "    for elem in where_0:\n",
    "        class_probs[elem[0], elem[1]] = 1 / \\\n",
    "            (kappa*class_counts.sum(axis=1)[elem[0]])\n",
    "    row_sums = class_probs.sum(axis=1)\n",
    "    class_probs = class_probs / row_sums[:, None]\n",
    "\n",
    "    # Place evaluation points in their corresponding leaf node.\n",
    "    # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "    eval_class_probs = class_probs[eval_nodes]\n",
    "    eval_entropies = [entropy(posterior, base=base)\n",
    "                      for posterior in eval_class_probs]\n",
    "    return np.mean(eval_entropies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf(X, y, n_estimators=300, max_samples=.4, base=2, kappa=3, reps=100, n_jobs=None):\n",
    "    # Build forest with default parameters.\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                              n_estimators=n_estimators,\n",
    "                              max_samples=max_samples,\n",
    "                              n_jobs=n_jobs,\n",
    "                              bootstrap=False)\n",
    "    model.fit(X, y)\n",
    "    n = X.shape[0]\n",
    "    K = model.n_classes_\n",
    "    _, y = np.unique(y, return_inverse=True)\n",
    "\n",
    "    cond_entropy = 0\n",
    "    final_null_dist = [0] * 100\n",
    "\n",
    "    tree_est_nodes = []\n",
    "    tree_eval_nodes = []\n",
    "    tree_unsampled_indices = []\n",
    "\n",
    "    # Get real test statistics\n",
    "    for tree_idx, tree in enumerate(model):\n",
    "        # Find the indices of the training set used for partition.\n",
    "        sampled_indices = model.estimators_samples_[tree_idx]\n",
    "        unsampled_indices = np.delete(np.arange(0, n), sampled_indices)\n",
    "        np.random.shuffle(unsampled_indices)\n",
    "        tree_unsampled_indices.append(unsampled_indices)\n",
    "\n",
    "        # Randomly split the rest into voting and evaluation.\n",
    "        vote_indices = unsampled_indices[:len(unsampled_indices)//2]\n",
    "        eval_indices = unsampled_indices[len(unsampled_indices)//2:]\n",
    "\n",
    "        # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "        # Posteriors in non-leaf cells will be zero everywhere\n",
    "        # and later changed to uniform.\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        class_counts = np.zeros((len(node_counts), K))\n",
    "        est_nodes = tree.apply(X[vote_indices])\n",
    "        tree_est_nodes.append(est_nodes)\n",
    "        eval_nodes = tree.apply(X[eval_indices])\n",
    "        tree_eval_nodes.append(eval_nodes)\n",
    "\n",
    "        cond_entropy += test_stat_helper(\n",
    "            est_nodes, eval_nodes, y[vote_indices], class_counts, K)\n",
    "\n",
    "    # Generate null dist\n",
    "    for j in range(reps):\n",
    "        for tree, unsampled_indices, est_nodes, eval_nodes in zip(\n",
    "            model, tree_unsampled_indices, tree_est_nodes, tree_eval_nodes\n",
    "        ):\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            class_counts = np.zeros((len(node_counts), K))\n",
    "            y_vote = y[unsampled_indices]\n",
    "            np.random.shuffle(y_vote)\n",
    "            final_null_dist[j] += test_stat_helper(\n",
    "                est_nodes, eval_nodes, y_vote[:len(unsampled_indices)//2], class_counts, K)\n",
    "\n",
    "    # note: shuffling y doesn't change these outputs\n",
    "    new_final_null_dist = [entropy([np.mean(\n",
    "        y), 1 - np.mean(y)], base=2) - val / n_estimators for val in final_null_dist]\n",
    "\n",
    "    final_stat = entropy([np.mean(y), 1 - np.mean(y)],\n",
    "                         base=2) - cond_entropy / n_estimators\n",
    "    return final_stat, new_final_null_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE_SIZE = 500\n",
    "STEP_SIZE = 100 \n",
    "SAMP_SIZES = range(100, MAX_SAMPLE_SIZE + STEP_SIZE, STEP_SIZE)\n",
    "POWER_REPS = 100\n",
    "\n",
    "SIMULATIONS = [\n",
    "    # \"linear\": \"Linear\",\n",
    "    # \"multimodal_independence\": \"Independence\"\n",
    "    # linear,\n",
    "    multimodal_independence\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "def estimate_power(sim, n_jobs=None):\n",
    "    samp_size_dict = dict()\n",
    "    samp_size_dict['sample_sizes'] = SAMP_SIZES\n",
    "    samp_size_dict['n_power_reps'] = POWER_REPS\n",
    "    power = []\n",
    "    for n_samples in SAMP_SIZES:\n",
    "        pvalues = []\n",
    "        samp_size_dict[n_samples] = {'stats': [], 'null_dists': []}\n",
    "        for p in tqdm(range(POWER_REPS)):\n",
    "            #plt.clf()\n",
    "            np.random.seed(None)\n",
    "            matrix1, matrix2 = multimodal_independence(n_samples, 2)\n",
    "            x, y = k_sample_transform([matrix1, matrix2])\n",
    "            stat, null_dist = uf(x, y.ravel(), n_jobs=n_jobs)\n",
    "            samp_size_dict[n_samples]['stats'].append(stat)\n",
    "            samp_size_dict[n_samples]['null_dists'].append(null_dist)\n",
    "            pvalue = np.mean(np.asarray(null_dist) >= stat)\n",
    "            print(\"P-value: \" + str(pvalue))\n",
    "            print(f'Test stat: {stat}')\n",
    "            print(f'Null dist: {null_dist[:5]}')\n",
    "            #if p % 4 == 0: \n",
    "                #plt.hist(null_dist)\n",
    "                #plt.axvline(stat, c='r', ls='--')\n",
    "            #plt.show()\n",
    "            pvalues.append(pvalue)\n",
    "        #plt.hist(pvalues, range=(0,1))\n",
    "        #plt.show()\n",
    "        ecdf = ECDF(pvalues)\n",
    "        plt.plot(ecdf.x, ecdf.y)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.xlabel(\"p-value\")\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel(\"fraction of data\")\n",
    "        plt.show()\n",
    "        power.append(np.mean(np.asarray(pvalues) <= 0.05))\n",
    "        #power.append((pvalues >= 0.05).sum() / POWER_REPS)\n",
    "\n",
    "    with open('multimodal_independence_power_reps.pkl', 'wb') as handle:\n",
    "        pickle.dump(samp_size_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    np.savetxt('C:/Users/siptest/Desktop/NDD/multimodal_independence_power1000.csv',\n",
    "               power, delimiter=',')\n",
    "\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                               | 1/100 [01:07<1:51:32, 67.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.14795680164144165\n",
      "Null dist: [0.14186699356589638, 0.14405184297227547, 0.1398056151681789, 0.13841311445315574, 0.14274966964198899]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                              | 2/100 [02:15<1:50:34, 67.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.14406575287598244\n",
      "Null dist: [0.14247201716999391, 0.1375670084472832, 0.13883579934323165, 0.13705964486178768, 0.14043367597632372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                             | 3/100 [03:23<1:49:21, 67.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.98\n",
      "Test stat: 0.1343657968177191\n",
      "Null dist: [0.1412951803418233, 0.1384249541660214, 0.13728286773345777, 0.1435481278117542, 0.13977656745688705]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                            | 4/100 [04:35<1:50:28, 69.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 1.0\n",
      "Test stat: 0.1353270120164871\n",
      "Null dist: [0.14492707990707587, 0.14068227448526727, 0.13756208825800953, 0.13979954841613162, 0.1421612476303733]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                            | 5/100 [05:43<1:48:51, 68.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 1.0\n",
      "Test stat: 0.13384522621649642\n",
      "Null dist: [0.1402057096412903, 0.14309938485770712, 0.14010969748429491, 0.14077458232385687, 0.1395750824248535]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                           | 6/100 [06:51<1:47:17, 68.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.99\n",
      "Test stat: 0.13331474976246527\n",
      "Null dist: [0.1393864269724886, 0.13988131837851214, 0.1403381580740446, 0.14200720187691052, 0.1375546130003541]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                          | 7/100 [07:59<1:46:04, 68.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.149344826005819\n",
      "Null dist: [0.1371532009220382, 0.13615241032379766, 0.13874134138095373, 0.1396404904273877, 0.1437861770717569]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                         | 8/100 [09:07<1:44:43, 68.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.77\n",
      "Test stat: 0.13804800190012567\n",
      "Null dist: [0.13976316580156323, 0.13929147616661075, 0.13740695431385863, 0.14334475799366087, 0.14356746452705083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                        | 9/100 [10:16<1:43:45, 68.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 1.0\n",
      "Test stat: 0.13433865039854653\n",
      "Null dist: [0.1421805525875237, 0.14237632858292237, 0.14139511728832188, 0.14586488452926727, 0.14006258769004942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 10/100 [11:24<1:42:21, 68.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.15905735404408305\n",
      "Null dist: [0.13527484334089002, 0.13733817743296184, 0.14207007512823377, 0.13752145812339567, 0.13701809636195283]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▋                                                                      | 11/100 [12:42<1:45:32, 71.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.05\n",
      "Test stat: 0.13896918204735675\n",
      "Null dist: [0.13230633151028992, 0.13039985585344538, 0.13458557581944208, 0.13388137260901634, 0.13612812872949387]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████▍                                                                     | 12/100 [14:02<1:48:33, 74.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.68\n",
      "Test stat: 0.14068985342980533\n",
      "Null dist: [0.14452658548065278, 0.14478969245663786, 0.14014179738132293, 0.13968373184674365, 0.1458366334264849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▎                                                                    | 13/100 [15:24<1:50:35, 76.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.48\n",
      "Test stat: 0.1407205670616768\n",
      "Null dist: [0.13961605193079607, 0.13942706197256338, 0.13913694943615684, 0.13718366648140057, 0.13794410424261172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████                                                                    | 14/100 [16:45<1:51:32, 77.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.49\n",
      "Test stat: 0.13964133022860492\n",
      "Null dist: [0.1412072854494888, 0.14148966603903657, 0.13648103024272717, 0.13910960160137975, 0.14101117400000795]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████▊                                                                   | 15/100 [18:14<1:54:55, 81.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.14645387088331197\n",
      "Null dist: [0.14219622309810864, 0.14140638911311465, 0.13819370129532837, 0.13826605150002957, 0.13627290891688215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████▋                                                                  | 16/100 [19:23<1:48:39, 77.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.14694088342914502\n",
      "Null dist: [0.13965466695014717, 0.13866497454582183, 0.14016372963583268, 0.13725119985262568, 0.1422548457892896]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▍                                                                 | 17/100 [20:45<1:49:06, 78.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.98\n",
      "Test stat: 0.1344977393783402\n",
      "Null dist: [0.14057070630304924, 0.1419255521436531, 0.13988124047211614, 0.13704933959811816, 0.13919282390565246]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▏                                                                | 18/100 [21:53<1:43:22, 75.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.14\n",
      "Test stat: 0.14139274774201305\n",
      "Null dist: [0.14134306187018186, 0.13945399882442933, 0.14051620227611994, 0.13930057036519583, 0.13840825101069276]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████                                                                | 19/100 [23:06<1:40:57, 74.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.01\n",
      "Test stat: 0.1418131959216199\n",
      "Null dist: [0.13454651803143203, 0.13588355420049847, 0.13521972676199956, 0.1374340097087463, 0.1377524425853488]\n"
     ]
    }
   ],
   "source": [
    "estimate_power(SIMULATIONS[0], n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_power2(): \n",
    "    \n",
    "    sim_title = [\n",
    "        #\"Linear\", \n",
    "        \"Independence\"\n",
    "    ]\n",
    "    sim = multimodal_independence\n",
    "    power = np.genfromtxt('C:/Users/siptest/Desktop/NDD/multimodal_independence_power1000.csv',\n",
    "                                      delimiter=',')\n",
    "    plt.plot(power)\n",
    "    plt.yticks([0, 1])\n",
    "    plt.axhline(y=0.05, color='b', linestyle='--')\n",
    "    positions = (0, 3, 5)\n",
    "    labels = (\"100\", \"65\", \"105\")\n",
    "    plt.xticks(positions, labels)\n",
    "    plt.xlabel(\"Sample Size\")\n",
    "    plt.ylabel(\"Mean Power from 100 Reps\")\n",
    "    plt.savefig(\"C:/Users/siptest/Desktop/NDD/Independence_UF_HonestSampling1000.jpg\", bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "C:/Users/siptest/Desktop/NDD/multimodal_independence_power1000.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ee15926e2d4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_power2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-720871f2cbf6>\u001b[0m in \u001b[0;36mplot_power2\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultimodal_independence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     power = np.genfromtxt('C:/Users/siptest/Desktop/NDD/multimodal_independence_power1000.csv',\n\u001b[1;32m---> 10\u001b[1;33m                                       delimiter=',')\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[0;32m   1747\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1749\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1750\u001b[0m             \u001b[0mfid_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    534\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: C:/Users/siptest/Desktop/NDD/multimodal_independence_power1000.csv not found."
     ]
    }
   ],
   "source": [
    "plot_power2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
