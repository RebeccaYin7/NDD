{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "import pickle\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree._classes import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "\n",
    "from hyppo.tools import multimodal_independence, indep_sim, rot_ksamp\n",
    "from hyppo.ksample._utils import k_sample_transform\n",
    "from tqdm import tqdm\n",
    "from hyppo.tools import * \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from proglearn import UncertaintyForest\n",
    "from joblib import Parallel, delayed\n",
    "sys.path.append('C:\\\\Users\\\\siptest\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stat_helper(vote_nodes, vote_classes, class_counts, K, kappa=3, base=2):\n",
    "    \"\"\"\n",
    "    est_nodes : list\n",
    "        Leaf indices used for voting\n",
    "    eval_nodes : list\n",
    "        Leaf indices in which a sample from the density subsample falls\n",
    "    est_classes : list\n",
    "        Voter class labels in est_node leaves\n",
    "    \"\"\"\n",
    "    for i in range(len(vote_nodes)):\n",
    "        class_counts[vote_nodes[i], vote_classes[i]] += 1\n",
    "\n",
    "    # Total number of estimation points in each leaf.\n",
    "    row_sums = class_counts.sum(axis=1)\n",
    "    row_sums[row_sums == 0] = 1  # Avoid divide by zero.\n",
    "    class_probs = class_counts / row_sums[:, None]\n",
    "\n",
    "    # Make the nodes that have no estimation indices uniform.\n",
    "    # This includes non-leaf nodes, but tha t will not affect the estimate.\n",
    "    class_probs[np.argwhere(class_probs.sum(axis=1) == 0)] = [1 / K]*K\n",
    "    # Apply finite sample correction and renormalize.\n",
    "    where_0 = np.argwhere(class_probs == 0)\n",
    "    for elem in where_0:\n",
    "        class_probs[elem[0], elem[1]] = 1 / \\\n",
    "            (kappa*class_counts.sum(axis=1)[elem[0]])\n",
    "    row_sums = class_probs.sum(axis=1)\n",
    "    class_probs = class_probs / row_sums[:, None]\n",
    "\n",
    "    # Place evaluation points in their corresponding leaf node.\n",
    "    # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "    vote_class_probs = class_probs[vote_nodes]\n",
    "    vote_entropies = [entropy(posterior, base=base)\n",
    "                      for posterior in vote_class_probs]\n",
    "    return np.mean(vote_entropies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf(X, y, n_estimators=5, max_samples=.63, base=2, kappa=3, reps=100, n_jobs=None):\n",
    "    # Build forest with default parameters.\n",
    "    model = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                              n_estimators=n_estimators,\n",
    "                              max_samples=max_samples,\n",
    "                              n_jobs=n_jobs,\n",
    "                              bootstrap=False)\n",
    "    model.fit(X, y)\n",
    "    n = X.shape[0]\n",
    "    K = model.n_classes_\n",
    "    _, y = np.unique(y, return_inverse=True)\n",
    "\n",
    "    cond_entropy = 0\n",
    "    final_null_dist = [0] * 100\n",
    "\n",
    "    #tree_est_nodes = []\n",
    "    #tree_eval_nodes = []\n",
    "    tree_vote_nodes = []\n",
    "    tree_unsampled_indices = []\n",
    "\n",
    "    # Get real test statistics\n",
    "    for tree_idx, tree in enumerate(model):\n",
    "        # Find the indices of the training set used for partition.\n",
    "        sampled_indices = model.estimators_samples_[tree_idx]\n",
    "        unsampled_indices = np.delete(np.arange(0, n), sampled_indices)\n",
    "        np.random.shuffle(unsampled_indices)\n",
    "        tree_unsampled_indices.append(unsampled_indices)\n",
    "\n",
    "        # Randomly split the rest into voting and evaluation.\n",
    "        #vote_indices = unsampled_indices[:len(unsampled_indices)//2]\n",
    "        #eval_indices = unsampled_indices[len(unsampled_indices)//2:]\n",
    "\n",
    "        # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "        # Posteriors in non-leaf cells will be zero everywhere\n",
    "        # and later changed to uniform.\n",
    "        node_counts = tree.tree_.n_node_samples\n",
    "        class_counts = np.zeros((len(node_counts), K))\n",
    "        vote_nodes = tree.apply(X[unsampled_indices])\n",
    "        tree_vote_nodes.append(vote_nodes)\n",
    "        \n",
    "        #est_nodes = tree.apply(X[vote_indices])\n",
    "        #tree_est_nodes.append(est_nodes)\n",
    "        #eval_nodes = tree.apply(X[eval_indices])\n",
    "        #tree_eval_nodes.append(eval_nodes)\n",
    "\n",
    "        cond_entropy += test_stat_helper(\n",
    "            vote_nodes, y[unsampled_indices], class_counts, K)\n",
    "\n",
    "    # Generate null dist\n",
    "    # normally 1000-10,000 reps for null \n",
    "    for j in range(reps):\n",
    "        for tree, unsampled_indices, vote_nodes in zip(\n",
    "            model, tree_unsampled_indices, tree_vote_nodes\n",
    "        ):\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            class_counts = np.zeros((len(node_counts), K))\n",
    "            y_vote = y[unsampled_indices]\n",
    "            np.random.shuffle(y_vote)\n",
    "            final_null_dist[j] += test_stat_helper(\n",
    "                vote_nodes, y_vote, class_counts, K)\n",
    "\n",
    "    # note: shuffling y doesn't change these outputs\n",
    "    new_final_null_dist = [entropy([np.mean(\n",
    "        y), 1 - np.mean(y)], base=2) - val / n_estimators for val in final_null_dist]\n",
    "\n",
    "    final_stat = entropy([np.mean(y), 1 - np.mean(y)],\n",
    "                         base=2) - cond_entropy / n_estimators\n",
    "    return final_stat, new_final_null_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(X): return entropy(X, axis=1, base = np.exp(1))\n",
    "uf = UncertaintyForest(n_estimators = 5, \n",
    "                       tree_construction_proportion=0.63, \n",
    "                       kappa = 3/2, \n",
    "                       honest_prior = \"ignore\", \n",
    "                       max_features = 1.0, \n",
    "                       n_jobs=-2,\n",
    "                      )\n",
    "\n",
    "matrix1, matrix2 = multimodal_independence(n_samples, 2)\n",
    "X, y = k_sample_transform([matrix1, matrix2])\n",
    "\n",
    "def func(x):\n",
    "        p = 0.5 * norm.pdf(x, mu, 1) + 0.5 * norm.pdf(x, -mu, 1)\n",
    "        return -p * np.log(p) / np.log(base)\n",
    "    \n",
    "# calculate norm factor - need compute_mutual_info & make_params\n",
    "\n",
    "_, counts = np.unique(y, return_counts=True)\n",
    "est_H_Y = entropy(counts, base=np.exp(1))\n",
    "value = (est_H_Y - uf.fit(X, y).apply_oob(X, ce)) / norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE_SIZE = 500\n",
    "STEP_SIZE = 100 \n",
    "SAMP_SIZES = range(100, MAX_SAMPLE_SIZE + STEP_SIZE, STEP_SIZE)\n",
    "POWER_REPS = 20\n",
    "\n",
    "SIMULATIONS = [\n",
    "    # \"linear\": \"Linear\",\n",
    "    # \"multimodal_independence\": \"Independence\"\n",
    "    # linear,\n",
    "    multimodal_independence\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "import matplotlib.pyplot as plt\n",
    "def estimate_power(sim, n_jobs=None):\n",
    "    samp_size_dict = dict()\n",
    "    samp_size_dict['sample_sizes'] = SAMP_SIZES\n",
    "    samp_size_dict['n_power_reps'] = POWER_REPS\n",
    "    power = []\n",
    "    pvalues_list = []\n",
    "    for n_samples in SAMP_SIZES:\n",
    "        pvalues = []\n",
    "        samp_size_dict[n_samples] = {'stats': [], 'null_dists': []}\n",
    "        for p in tqdm(range(POWER_REPS)):\n",
    "            #plt.clf()\n",
    "            np.random.seed(None)\n",
    "            #matrix1, matrix2 = multimodal_independence(n_samples, 2)\n",
    "            #x, y = k_sample_transform([matrix1, matrix2])\n",
    "            #x, y = linear(n_samples, 2)\n",
    "            x, y = rot_ksamp('multimodal_independence', n=100, p=3, noise=True)\n",
    "            x, y = k_sample_transform([x, y])\n",
    "            #print(x)\n",
    "            #print(y)\n",
    "            #y = list(map(lambda sub: list(map(int, sub)), y))\n",
    "            y = y.astype(int)\n",
    "            stat, null_dist = uf(x, y, n_jobs=n_jobs)\n",
    "            #stat, null_dist = uf(x, y.ravel(), n_jobs=n_jobs)\n",
    "            samp_size_dict[n_samples]['stats'].append(stat)\n",
    "            samp_size_dict[n_samples]['null_dists'].append(null_dist)\n",
    "            pvalue = np.mean(np.asarray(null_dist) >= stat)\n",
    "            print(\"P-value: \" + str(pvalue))\n",
    "            print(f'Test stat: {stat}')\n",
    "            print(f'Null dist: {null_dist[:5]}')\n",
    "            #if p % 4 == 0: \n",
    "                #plt.hist(null_dist)\n",
    "                #plt.axvline(stat, c='r', ls='--')\n",
    "            #plt.show()\n",
    "            pvalues.append(pvalue)\n",
    "        pvalues_list.append(pvalues)\n",
    "        #plt.hist(pvalues, range=(0,1))\n",
    "        #plt.show()\n",
    "        axes = plt.gca()\n",
    "        x_vals = np.array(axes.get_xlim())\n",
    "        y_vals = 1 * x_vals\n",
    "        plt.plot(x_vals, y_vals, '--')\n",
    "        ecdf = ECDF(pvalues)\n",
    "        plt.plot(ecdf.x, ecdf.y)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.xlabel(\"p-value\")\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.ylabel(\"fraction of data\")\n",
    "        plt.show()\n",
    "        power.append(np.mean(np.asarray(pvalues) <= 0.05))\n",
    "        #power.append((pvalues >= 0.05).sum() / POWER_REPS)\n",
    "\n",
    "    #with open('multimodal_independence_power_reps.pkl', 'wb') as handle:\n",
    "        #pickle.dump(samp_size_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('linear_power_reps.pkl', 'wb') as handle:\n",
    "        pickle.dump(samp_size_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    np.savetxt('C:/Users/siptest/Desktop/NDD/linear_honest_3-31.csv',\n",
    "               power, delimiter=',')\n",
    "\n",
    "    return power, pvalues_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "  5%|████▏                                                                              | 1/20 [00:01<00:19,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.0\n",
      "Test stat: 0.19813076235282878\n",
      "Null dist: [0.129142318152906, 0.15036498284112698, 0.14558059496226572, 0.1535700496048854, 0.10904457995098105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      " 10%|████████▎                                                                          | 2/20 [00:02<00:19,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.89\n",
      "Test stat: 0.11549345380400311\n",
      "Null dist: [0.12819150458924367, 0.1184999518853489, 0.1320765179892781, 0.12046070983155732, 0.15404257331687377]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      " 15%|████████████▍                                                                      | 3/20 [00:03<00:18,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.21\n",
      "Test stat: 0.15611071735801052\n",
      "Null dist: [0.1553394026455519, 0.12985088057654404, 0.1492619762655799, 0.13695628919406033, 0.17934808378628353]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      " 20%|████████████████▌                                                                  | 4/20 [00:04<00:16,  1.01s/it]C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.6\n",
      "Test stat: 0.12176437876904633\n",
      "Null dist: [0.11789784047633989, 0.118875622267959, 0.14282889862552395, 0.1567729917117784, 0.14514230664061967]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 5/20 [00:05<00:14,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.53\n",
      "Test stat: 0.13724037901533848\n",
      "Null dist: [0.11067206522370976, 0.16077642453614605, 0.09079190657657321, 0.11842661411689215, 0.14895527483128546]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      " 25%|████████████████████▊                                                              | 5/20 [00:05<00:17,  1.19s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-a08c4efd5ea1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpower\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalues_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimate_power\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSIMULATIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-81-1b02e824584e>\u001b[0m in \u001b[0;36mestimate_power\u001b[1;34m(sim, n_jobs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#y = list(map(lambda sub: list(map(int, sub)), y))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mstat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;31m#stat, null_dist = uf(x, y.ravel(), n_jobs=n_jobs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0msamp_size_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stats'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-cc46085b366e>\u001b[0m in \u001b[0;36muf\u001b[1;34m(X, y, n_estimators, max_samples, base, kappa, reps, n_jobs)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_vote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             final_null_dist[j] += test_stat_helper(\n\u001b[1;32m---> 60\u001b[1;33m                 vote_nodes, y_vote, class_counts, K)\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# note: shuffling y doesn't change these outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-44b2e9264eee>\u001b[0m in \u001b[0;36mtest_stat_helper\u001b[1;34m(vote_nodes, vote_classes, class_counts, K, kappa, base)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mvote_class_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvote_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     vote_entropies = [entropy(posterior, base=base)\n\u001b[1;32m---> 33\u001b[1;33m                       for posterior in vote_class_probs]\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote_entropies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-44b2e9264eee>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mvote_class_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvote_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     vote_entropies = [entropy(posterior, base=base)\n\u001b[1;32m---> 33\u001b[1;33m                       for posterior in vote_class_probs]\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote_entropies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36mentropy\u001b[1;34m(pk, qk, base, axis)\u001b[0m\n\u001b[0;32m   2671\u001b[0m         \u001b[0mqk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mqk\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2672\u001b[0m         \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrel_entr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2673\u001b[1;33m     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2675\u001b[0m         \u001b[0mS\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2241\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2242\u001b[1;33m                           initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "power, pvalues_list = estimate_power(SIMULATIONS[0], n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_power2(): \n",
    "    \n",
    "    sim_title = [\n",
    "        \"Linear\", \n",
    "        #\"Independence\"\n",
    "    ]\n",
    "    sim = multimodal_independence\n",
    "    power = np.genfromtxt('C:/Users/siptest/Desktop/NDD/linear_honest_3-31.csv',\n",
    "                                      delimiter=',')\n",
    "    plt.plot(power)\n",
    "    plt.yticks([0, 1])\n",
    "    plt.axhline(y=0.05, color='b', linestyle='--')\n",
    "    positions = (0, 3, 5)\n",
    "    labels = (\"100\", \"300\", \"500\")\n",
    "    plt.xticks(positions, labels)\n",
    "    plt.xlabel(\"Sample Size\")\n",
    "    plt.ylabel(\"Mean Power from 100 Reps\")\n",
    "    plt.savefig(\"C:/Users/siptest/Desktop/NDD/linear_honest_3-31.jpg\", bbox_inches='tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_power2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
