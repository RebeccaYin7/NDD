{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import hyppo\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from hyppo.independence.base import IndependenceTest\n",
    "from hyppo._utils import perm_test\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree._classes import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "from scipy.integrate import nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from hyppo.sims import *\n",
    "from hyppo.ksample._utils import k_sample_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarks import power_2samp_sample\n",
    "from hyppo.independence import CCA, Dcorr, HHG, Hsic, RV, MGC\n",
    "from hyppo.sims import *\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "sys.path\n",
    "#sys.path.append('C:\\\\Users\\\\siptest\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\Scripts')\n",
    "#sys.path.append('C:\\\\Users\\\\siptest\\\\Desktop\\\\R-3.6.2\\\\bin\\\\x64')\n",
    "\n",
    "import sys, os\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True, style='white', context='talk', font_scale=2)\n",
    "PALETTE = sns.color_palette(\"Set1\")\n",
    "sns.set_palette(PALETTE[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UF(IndependenceTest): \n",
    "    def _init_(self, compute_distance='euclidean', bias = False, **kwargs): \n",
    "        self._name_= \"UF\"\n",
    "        IndepedenceTest._init_(self)\n",
    "        \n",
    "    def test_stat_helper(self, tree, tree_idx, X, y, sampled_indices, unsampled_indices, conditional_entropy, K, model, kappa = 3, base = 2): \n",
    "        # Randomly split the rest into voting and evaluation.\n",
    "            \n",
    "            total_unsampled = len(unsampled_indices)\n",
    "            np.random.shuffle(unsampled_indices)\n",
    "            vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "            eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "            \n",
    "            # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "            # Posteriors in non-leaf cells will be zero everywhere\n",
    "            # and later changed to uniform.\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            class_counts = np.zeros((len(node_counts), K))\n",
    "            est_nodes = tree.apply(X[vote_indices])\n",
    "            est_classes = y[vote_indices]\n",
    "            for i in range(len(est_nodes)):\n",
    "                class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "            \n",
    "            row_sums = class_counts.sum(axis=1) # Total number of estimation points in each leaf.\n",
    "            row_sums[row_sums == 0] = 1 # Avoid divide by zero.\n",
    "            class_probs = class_counts / row_sums[:, None]\n",
    "            \n",
    "            # Make the nodes that have no estimation indices uniform.\n",
    "            # This includes non-leaf nodes, but tha t will not affect the estimate.\n",
    "            class_probs[np.argwhere(class_probs.sum(axis = 1) == 0)] = [1 / K]*K\n",
    "            # Apply finite sample correction and renormalize.\n",
    "            where_0 = np.argwhere(class_probs == 0)\n",
    "            for elem in where_0:\n",
    "                class_probs[elem[0], elem[1]] = 1 / (kappa*class_counts.sum(axis = 1)[elem[0]])\n",
    "            row_sums = class_probs.sum(axis=1)\n",
    "            class_probs = class_probs / row_sums[:, None]\n",
    "            \n",
    "            # Place evaluation points in their corresponding leaf node.\n",
    "            # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "            eval_class_probs = class_probs[tree.apply(X[eval_indices])]\n",
    "            # eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "            eval_entropies = [entropy(posterior, base = base) for posterior in eval_class_probs]\n",
    "            cond_entropy += np.mean(eval_entropies)\n",
    "            return cond_entropy\n",
    "        \n",
    "    #def uf(self, X, y, n_estimators = 300, max_samples = .4, base = np.exp(1), kappa = 3):\n",
    "    def uf(self, X, y, n_estimators = 300, max_samples = .4, base = 2, kappa = 3):    \n",
    "        # Build forest with default parameters.\n",
    "        model = BaggingClassifier(DecisionTreeClassifier(), \n",
    "                                  n_estimators=n_estimators, \n",
    "                                  max_samples=max_samples, \n",
    "                                  bootstrap=False)\n",
    "        model.fit(X, y)\n",
    "        n = X.shape[0]\n",
    "        K = model.n_classes_\n",
    "        _, y = np.unique(y, return_inverse=True)\n",
    "        \n",
    "        cond_entropy = 0\n",
    "        null_cond_entropy = 0\n",
    "        null_dist = []\n",
    "        for tree_idx, tree in enumerate(model):\n",
    "            # Find the indices of the training set used for partition.\n",
    "            sampled_indices = model.estimators_samples_[tree_idx]\n",
    "            unsampled_indices = np.delete(np.arange(0,n), sampled_indices)\n",
    "\n",
    "            #test_stat = self.test_stat_helper(tree, tree_idx, X, y, sampled_indices, unsampled_indices, cond_entropy, K, model)\n",
    "            total_unsampled = len(unsampled_indices)\n",
    "            np.random.shuffle(unsampled_indices)\n",
    "            vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "            eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "            \n",
    "            # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "            # Posteriors in non-leaf cells will be zero everywhere\n",
    "            # and later changed to uniform.\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            class_counts = np.zeros((len(node_counts), K))\n",
    "            est_nodes = tree.apply(X[vote_indices])\n",
    "            est_classes = y[vote_indices]\n",
    "            for i in range(len(est_nodes)):\n",
    "                class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "            \n",
    "            row_sums = class_counts.sum(axis=1) # Total number of estimation points in each leaf.\n",
    "            row_sums[row_sums == 0] = 1 # Avoid divide by zero.\n",
    "            class_probs = class_counts / row_sums[:, None]\n",
    "            \n",
    "            # Make the nodes that have no estimation indices uniform.\n",
    "            # This includes non-leaf nodes, but tha t will not affect the estimate.\n",
    "            class_probs[np.argwhere(class_probs.sum(axis = 1) == 0)] = [1 / K]*K\n",
    "            # Apply finite sample correction and renormalize.\n",
    "            where_0 = np.argwhere(class_probs == 0)\n",
    "            for elem in where_0:\n",
    "                class_probs[elem[0], elem[1]] = 1 / (kappa*class_counts.sum(axis = 1)[elem[0]])\n",
    "            row_sums = class_probs.sum(axis=1)\n",
    "            class_probs = class_probs / row_sums[:, None]\n",
    "            \n",
    "            # Place evaluation points in their corresponding leaf node.\n",
    "            # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "            eval_class_probs = class_probs[tree.apply(X[eval_indices])]\n",
    "            # eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "            eval_entropies = [entropy(posterior, base = base) for posterior in eval_class_probs]\n",
    "            cond_entropy += np.mean(eval_entropies)\n",
    "            return cond_entropy\n",
    "        \n",
    "            tree_null_stats = []\n",
    "            null_stat = 0\n",
    "            # 100 is reps - since we didn't pass in \n",
    "            for _ in range(100): \n",
    "                shuffle_y = np.random.shuffle(y[unsampled_indices])\n",
    "                #null_stat = self.test_stat_helper(tree, X, shuffle_y, sampled_indices, unsampled_indices, null_cond_entropy, K)\n",
    "                #total_unsampled = len(unsampled_indices)\n",
    "                #np.random.shuffle(unsampled_indices)\n",
    "                #vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "                #eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "\n",
    "                # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "                # Posteriors in non-leaf cells will be zero everywhere\n",
    "                # and later changed to uniform.\n",
    "                node_counts = tree.tree_.n_node_samples\n",
    "                class_counts = np.zeros((len(node_counts), K))\n",
    "                est_nodes = tree.apply(X[vote_indices])\n",
    "                est_classes = shuffle_y[vote_indices]\n",
    "                for i in range(len(est_nodes)):\n",
    "                    class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "\n",
    "                row_sums = class_counts.sum(axis=1) # Total number of estimation points in each leaf.\n",
    "                row_sums[row_sums == 0] = 1 # Avoid divide by zero.\n",
    "                class_probs = class_counts / row_sums[:, None]\n",
    "\n",
    "                # Make the nodes that have no estimation indices uniform.\n",
    "                # This includes non-leaf nodes, but tha t will not affect the estimate.\n",
    "                class_probs[np.argwhere(class_probs.sum(axis = 1) == 0)] = [1 / K]*K\n",
    "                # Apply finite sample correction and renormalize.\n",
    "                where_0 = np.argwhere(class_probs == 0)\n",
    "                for elem in where_0:\n",
    "                    class_probs[elem[0], elem[1]] = 1 / (kappa*class_counts.sum(axis = 1)[elem[0]])\n",
    "                row_sums = class_probs.sum(axis=1)\n",
    "                class_probs = class_probs / row_sums[:, None]\n",
    "\n",
    "                # Place evaluation points in their corresponding leaf node.\n",
    "                # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "                eval_class_probs = class_probs[tree.apply(X[eval_indices])]\n",
    "                # eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "                eval_entropies = [entropy(posterior, base = base) for posterior in eval_class_probs]\n",
    "                null_stat += np.mean(eval_entropies)\n",
    "                #return null_stat\n",
    "                tree_null_stats.append(null_stat)\n",
    "            null_dist.append(tree_null_stats) \n",
    "        \n",
    "        final_null_dist = []\n",
    "        #each list of nulls from trees \n",
    "        for i in range(100): \n",
    "            #values in each list of nulls\n",
    "            for j in range(100):\n",
    "                temp += null_dist[j][i]\n",
    "            final_null_dist.append(temp/100)\n",
    "        print(final_null_dist)\n",
    "         \n",
    "        #print(entropy([np.mean(y), 1 - np.mean(y)], base = 2))\n",
    "        #print(entropy([np.mean(y), 1 - np.mean(y)], base = 2) - cond_entropy / n_estimators)\n",
    "        final_stat = entropy([np.mean(y), 1 - np.mean(y)], base = 2) - cond_entropy / n_estimators\n",
    "        return final_stat, final_null_dist\n",
    "    \n",
    "    def _statistic(self, X, y): \n",
    "        stat, null_dist = self.uf(X, y)\n",
    "        self.stat = stat\n",
    "        num = 0\n",
    "        for val in null_dist: \n",
    "            if null_dist <= stat: \n",
    "                num = num + 1\n",
    "        pvalue = num / 100 \n",
    "        #pvalue = (null_dist <= self.stat).sum() / 100     \n",
    "        return stat, pvalue\n",
    "    #def test(self, X, y): \n",
    "        #return self.perm_test(X, y)\n",
    "    def test(self, X, y, reps = 100, workers = -1):\n",
    "        #stat, pvalue, _ = perm_test(self._statistic, X, y, reps = reps, is_distsim=True)\n",
    "        stat, pvalue = self._statistic(X, y)\n",
    "        self.stat = stat\n",
    "        self.pvalue = pvalue\n",
    "        \n",
    "        return stat, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE_SIZE = 100\n",
    "STEP_SIZE = 20\n",
    "SAMP_SIZES = range(5, MAX_SAMPLE_SIZE + STEP_SIZE, STEP_SIZE)\n",
    "#POWER_REPS = 5\n",
    "POWER_REPS = 5 \n",
    "\n",
    "SIMULATIONS = [\n",
    "    #\"linear\": \"Linear\",\n",
    "    #\"multimodal_independence\": \"Independence\"\n",
    "    #linear, \n",
    "    multimodal_independence\n",
    "]\n",
    "\n",
    "TESTS = [\n",
    "    UF, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_power(sim, test):\n",
    "    #est_power = np.array([np.mean([power_2samp_sample(test, trans_2samp, sim, n=i) for _ in range(POWER_REPS)])\n",
    "                          #for i in SAMP_SIZES])\n",
    "    est_power = []\n",
    "    for i in SAMP_SIZES: \n",
    "        power = np.mean([power_2samp_sample(test, trans_2samp, sim, n=i, p = 1, reps = 100, workers = 1) for _ in range(POWER_REPS)])\n",
    "        est_power.append(power)\n",
    "        np.savetxt('C:/Users/siptest/Desktop/NDD/{}_{}1D_HonestSampling.csv'.format(sim.__name__, \"UF\"),\n",
    "               est_power, delimiter=',')\n",
    "    \n",
    "    return est_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.9s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-11-252bb80e4f1e>\", line 6, in estimate_power\n  File \"<ipython-input-11-252bb80e4f1e>\", line 6, in <listcomp>\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power_2samp.py\", line 220, in power_2samp_sample\n    random_state=random_state,\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power_2samp.py\", line 162, in power\n    random_state=random_state,\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power_2samp.py\", line 109, in _perm_test\n    alt_dist, null_dist = map(list, zip(*list(mapwrapper(parallelp, range(reps)))))\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power_2samp.py\", line 45, in __call__\n    obs_stat = self.test._statistic(u, v)\n  File \"<ipython-input-4-b830844a7a3a>\", line 164, in _statistic\nTypeError: 'numpy.float64' object is not iterable\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d9e82677fbee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m outputs = Parallel(n_jobs=-1, verbose=100)(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimate_power\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSIMULATIONS\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTESTS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#estimate_power(sim, test) for sim in SIMULATIONS for test in TESTS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#outputs = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "outputs = Parallel(n_jobs=-1, verbose=100)(\n",
    "    [delayed(estimate_power)(sim, test) for sim in SIMULATIONS for test in TESTS]\n",
    ")\n",
    "#estimate_power(sim, test) for sim in SIMULATIONS for test in TESTS\n",
    "#outputs = []\n",
    "#for test in TESTS: \n",
    "    #for sim in SIMULATIONS:\n",
    "        #estimate_power(sim, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power2(): \n",
    "    \n",
    "    sim_title = [\n",
    "        #\"Linear\", \n",
    "        \"Independence\"\n",
    "    ]\n",
    "    sim = multimodal_independence\n",
    "    power = np.genfromtxt('C:/Users/siptest/Desktop/NDD/{}_{}3D5Power.csv'.format(sim.__name__, \"UF\"),\n",
    "                                      delimiter=',')\n",
    "    plt.plot(power)\n",
    "    plt.yticks([0, 1])\n",
    "    plt.axhline(y=0.05, color='b', linestyle='--')\n",
    "    positions = (0, 3, 5)\n",
    "    labels = (\"5\", \"65\", \"105\")\n",
    "    plt.xticks(positions, labels)\n",
    "    plt.xlabel(\"Sample Size\")\n",
    "    plt.ylabel(\"Mean Power from 5 Reps\")\n",
    "    plt.savefig(\"C:/Users/siptest/Desktop/NDD/Independence_UF_3D5PowerFig.jpg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power(): \n",
    "    fig, ax = plt.subplots(nrows = 1, ncols =1, figsize = (28, 24))\n",
    "    \n",
    "    sim_title = [\n",
    "        #\"Linear\", \n",
    "        \"Independence\"\n",
    "    ]\n",
    "        \n",
    "    for i, col in enumerate(ax):\n",
    "        sim = SIMULATIONS[i]\n",
    "        for test in TESTS:\n",
    "                power = np.genfromtxt('C:/Users/siptest/Desktop/NDD/{}_{}3D5Power.csv'.format(sim.__name__, \"UF\"),\n",
    "                                      delimiter=',')\n",
    "        col.plot(SAMP_SIZES, power, label=\"UF\", lw=1)\n",
    "        col.set_xticks([])\n",
    "        col.set_yticks([0, 1])\n",
    "        col.set_title(sim_title[i])\n",
    "        if sim == multimodal_independence: \n",
    "            plt.axhline(y=0.05, color='b', linestyle='--')\n",
    "\n",
    "    fig.text(0.5, 0.08, 'Sample Size', ha='center')\n",
    "    fig.text(0.07, 0.5, 'Statistical Power', va='center', rotation='vertical')\n",
    "    leg = plt.legend(bbox_to_anchor=(0.5, 0.08), bbox_transform=plt.gcf().transFigure,\n",
    "                     ncol=5, loc='upper center')\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(5.0)\n",
    "    plt.subplots_adjust(hspace=.50)\n",
    "    plt.savefig('C:/Users/siptest/Desktop/NDD/2samp_power_indep3D5Power.png', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
