{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyppo-benchmarks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-26242f285884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hyppo-benchmarks.power\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"hyppo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hyppo-benchmarks'"
     ]
    }
   ],
   "source": [
    "from benchmarks import power_sample\n",
    "from hyppo.independence import CCA, Dcorr, HHG, Hsic, RV, MGC\n",
    "from hyppo.sims import *\n",
    "from hyppo.sims import indep_sim\n",
    "\n",
    "import sys, os\n",
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "hb = importlib.import_module(\"hyppo-benchmarks.power\", \"hyppo\")\n",
    "from hb.rf import power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyppo\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from hyppo.independence.base import IndependenceTest\n",
    "from hyppo._utils import perm_test\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree._classes import DecisionTreeClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import entropy, multivariate_normal\n",
    "from scipy.integrate import nquad\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "sys.path\n",
    "sys.path.append('C:\\\\Users\\\\siptest\\\\AppData\\\\Roaming\\\\Python\\\\Python36\\\\Scripts')\n",
    "sys.path.append('C:\\\\Users\\\\siptest\\\\Desktop\\\\R-3.6.2\\\\bin\\\\x64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(color_codes=True, style='white', context='talk', font_scale=2)\n",
    "PALETTE = sns.color_palette(\"Set1\")\n",
    "sns.set_palette(PALETTE[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UF(): \n",
    "    \n",
    "    def _init_(self): \n",
    "        self._name_ = \"UF\"\n",
    "            \n",
    "    def _statistic(self, X, y):\n",
    "        n = 20 \n",
    "        d = 2\n",
    "        pis = [0.05 * i for i in range(1,20)]\n",
    "        num_trials = 10\n",
    "     \n",
    "        return self.mi(X, y, n, d, pis, num_trials)\n",
    "        \n",
    "    def uf(self, X, y, n_estimators = 300, max_samples = .4, base = np.exp(1), kappa = 3):\n",
    "        \n",
    "        # Build forest with default parameters.\n",
    "        model = BaggingClassifier(DecisionTreeClassifier(), \n",
    "                                  n_estimators=n_estimators, \n",
    "                                  max_samples=max_samples, \n",
    "                                  bootstrap=False)\n",
    "        model.fit(X, y)\n",
    "        n = X.shape[0]\n",
    "        K = model.n_classes_\n",
    "        _, y = np.unique(y, return_inverse=True)\n",
    "        \n",
    "        cond_entropy = 0\n",
    "        for tree_idx, tree in enumerate(model):\n",
    "            # Find the indices of the training set used for partition.\n",
    "            sampled_indices = model.estimators_samples_[tree_idx]\n",
    "            unsampled_indices = np.delete(np.arange(0,n), sampled_indices)\n",
    "            \n",
    "            # Randomly split the rest into voting and evaluation.\n",
    "            total_unsampled = len(unsampled_indices)\n",
    "            np.random.shuffle(unsampled_indices)\n",
    "            vote_indices = unsampled_indices[:total_unsampled//2]\n",
    "            eval_indices = unsampled_indices[total_unsampled//2:]\n",
    "            \n",
    "            # Store the posterior in a num_nodes-by-num_classes matrix.\n",
    "            # Posteriors in non-leaf cells will be zero everywhere\n",
    "            # and later changed to uniform.\n",
    "            node_counts = tree.tree_.n_node_samples\n",
    "            class_counts = np.zeros((len(node_counts), K))\n",
    "            est_nodes = tree.apply(X[vote_indices])\n",
    "            est_classes = y[vote_indices]\n",
    "            for i in range(len(est_nodes)):\n",
    "                class_counts[est_nodes[i], est_classes[i]] += 1\n",
    "            \n",
    "            row_sums = class_counts.sum(axis=1) # Total number of estimation points in each leaf.\n",
    "            row_sums[row_sums == 0] = 1 # Avoid divide by zero.\n",
    "            class_probs = class_counts / row_sums[:, None]\n",
    "            \n",
    "            # Make the nodes that have no estimation indices uniform.\n",
    "            # This includes non-leaf nodes, but that will not affect the estimate.\n",
    "            class_probs[np.argwhere(class_probs.sum(axis = 1) == 0)] = [1 / K]*K\n",
    "            \n",
    "            # Apply finite sample correction and renormalize.\n",
    "            where_0 = np.argwhere(class_probs == 0)\n",
    "            for elem in where_0:\n",
    "                class_probs[elem[0], elem[1]] = 1 / (kappa*class_counts.sum(axis = 1)[elem[0]])\n",
    "            row_sums = class_probs.sum(axis=1)\n",
    "            class_probs = class_probs / row_sums[:, None]\n",
    "            \n",
    "            # Place evaluation points in their corresponding leaf node.\n",
    "            # Store evaluation posterior in a num_eval-by-num_class matrix.\n",
    "            eval_class_probs = class_probs[tree.apply(X[eval_indices])]\n",
    "            # eval_class_probs = [class_probs[x] for x in tree.apply(X[eval_indices])]\n",
    "            eval_entropies = [entropy(posterior) for posterior in eval_class_probs]\n",
    "            cond_entropy += np.mean(eval_entropies)\n",
    "    \n",
    "          \n",
    "        return cond_entropy / n_estimators\n",
    "            \n",
    "    def generate_data2(n, d, mu = 1):\n",
    "        n_1 = np.random.binomial(n, .5) # number of class 1\n",
    "        mean = np.zeros(d)\n",
    "        mean[0] = mu\n",
    "        X_1 = np.random.multivariate_normal(mean, np.eye(d), n_1)\n",
    "        \n",
    "        X = np.concatenate((X_1, np.random.multivariate_normal(-mean, np.eye(d), n - n_1)))\n",
    "        y = np.concatenate((np.repeat(1, n_1), np.repeat(0, n - n_1)))\n",
    "      \n",
    "        return X, y\n",
    "    \n",
    "    def generate_data(self, n, d, mu = 1, var1 = 1, pi = 0.5, three_class = False):\n",
    "        \n",
    "        means, Sigmas, probs = self._make_params(d, mu = mu, var1 = var1, pi = pi, three_class = three_class)\n",
    "        counts = np.random.multinomial(n, probs, size = 1)[0]\n",
    "        \n",
    "        X_data = []\n",
    "        y_data = []\n",
    "        for k in range(len(probs)):\n",
    "            X_data.append(np.random.multivariate_normal(means[k], Sigmas[k], counts[k]))\n",
    "            y_data.append(np.repeat(k, counts[k]))\n",
    "        X = np.concatenate(tuple(X_data))\n",
    "        y = np.concatenate(tuple(y_data))\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def _make_params(self, d, mu = 1, var1 = 1, pi = 0.5, three_class = False):\n",
    "        \n",
    "        if three_class:\n",
    "            return self._make_three_class_params(d, mu, pi)\n",
    "        \n",
    "        mean = np.zeros(d)\n",
    "        mean[0] = mu\n",
    "        means = [mean, -mean]\n",
    "    \n",
    "        Sigma1 = np.eye(d)\n",
    "        Sigma1[0, 0] = var1\n",
    "        Sigmas = [np.eye(d), Sigma1]\n",
    "        \n",
    "        probs = [pi, 1 - pi]\n",
    "        \n",
    "        return means, Sigmas, probs\n",
    "    \n",
    "    def _make_three_class_params(d, mu, pi):\n",
    "        \n",
    "        means = []\n",
    "        mean = np.zeros(d)\n",
    "        \n",
    "        mean[0] = mu\n",
    "        means.append(copy.deepcopy(mean))\n",
    "        \n",
    "        mean[0] = -mu\n",
    "        means.append(copy.deepcopy(mean))\n",
    "        \n",
    "        mean[0] = 0\n",
    "        mean[d-1] = mu\n",
    "        means.append(copy.deepcopy(mean))\n",
    "        \n",
    "        Sigmas = [np.eye(d)]*3\n",
    "        probs = [pi, (1 - pi) / 2, (1 - pi) / 2]\n",
    "        \n",
    "        return means, Sigmas, probs\n",
    "    \n",
    "    def compute_mutual_info(self, d, base = np.exp(1), mu = 1, var1 = 1, pi = 0.5, three_class = False):\n",
    "        \n",
    "        if d > 1:\n",
    "            dim = 2\n",
    "        else:\n",
    "            dim = 1\n",
    "     \n",
    "        means, Sigmas, probs = self._make_params(dim, mu = mu, var1 = var1, pi = pi, three_class = three_class)\n",
    "        \n",
    "        # Compute entropy and X and Y.\n",
    "        def func(*args):\n",
    "            x = np.array(args)\n",
    "            p = 0\n",
    "            for k in range(len(means)):\n",
    "                p += probs[k] * multivariate_normal.pdf(x, means[k], Sigmas[k])\n",
    "            return -p * np.log(p) / np.log(base)\n",
    "    \n",
    "        scale = 10\n",
    "        lims = [[-scale, scale]]*dim\n",
    "        H_X, int_err = nquad(func, lims)\n",
    "        H_Y = entropy(probs, base = base)\n",
    "        \n",
    "        # Compute MI.\n",
    "        H_XY = 0\n",
    "        for k in range(len(means)):\n",
    "            H_XY += probs[k] * (dim * np.log(2*np.pi) + np.log(np.linalg.det(Sigmas[k])) + dim) / (2 * np.log(base))\n",
    "        I_XY = H_X - H_XY\n",
    "        \n",
    "        return I_XY, H_X, H_Y\n",
    "    \n",
    "    def estimate_mi(self, X, y, est_H_Y, norm_factor): \n",
    "        \n",
    "        print(np.array(X))\n",
    "        print(y)\n",
    "        \n",
    "        return (est_H_Y - self.uf(np.array(X), y)) / norm_factor\n",
    "\n",
    "    \n",
    "    def mi(self, X, y, n, d, pis, num_trials):\n",
    "        #def worker(t): \n",
    "            #X, y = generate_data(n, d, pi = elem)\n",
    "            \n",
    "            #I_XY, H_X, H_Y = compute_mutual_info(d, pi = elem)\n",
    "            I_XY, H_X, H_Y = self.compute_mutual_info(d)\n",
    "            norm_factor = min(H_X, H_Y)\n",
    "            \n",
    "            _, counts = np.unique(y, return_counts=True)\n",
    "            est_H_Y = entropy(counts, base=np.exp(1))\n",
    "            ret = []\n",
    "            ret.append(self.estimate_mi(X, y, est_H_Y, norm_factor))\n",
    "            #return tuple(ret)\n",
    "            return ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLE_SIZE = 100\n",
    "STEP_SIZE = 5\n",
    "SAMP_SIZES = range(5, MAX_SAMPLE_SIZE + STEP_SIZE, STEP_SIZE)\n",
    "POWER_REPS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = [\n",
    "    linear,\n",
    "    multiplicative_noise,\n",
    "    multimodal_independence\n",
    "]\n",
    "\n",
    "tests = [\n",
    "    UF, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_power(sim, test):\n",
    "    est_power = np.array([np.mean([power_sample(test, sim, n=i) for _ in range(POWER_REPS)])\n",
    "                          for i in SAMP_SIZES])\n",
    "    np.savetxt('C:/Users/siptest/Desktop/hyppo/benchmarks/2samp_vs_samplesize/{}_{}.csv'.format(sim.__name__, test.__name__),\n",
    "               est_power, delimiter=',')\n",
    "    \n",
    "    return est_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.3s remaining:    0.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"<ipython-input-7-e30cd2ee619b>\", line 3, in estimate_power\n  File \"<ipython-input-7-e30cd2ee619b>\", line 3, in <listcomp>\n  File \"<ipython-input-7-e30cd2ee619b>\", line 2, in <listcomp>\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power.py\", line 174, in power_sample\n    random_state=random_state,\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power.py\", line 122, in power\n    random_state=random_state,\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power.py\", line 75, in _perm_test\n    alt_dist, null_dist = map(list, zip(*list(mapwrapper(parallelp, range(reps)))))\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\benchmarks\\power.py\", line 31, in __call__\n    obs_stat = self.test._statistic(x, y)\n  File \"<ipython-input-4-5e54a5f57af4>\", line 12, in _statistic\n  File \"<ipython-input-4-5e54a5f57af4>\", line 185, in mi\n  File \"<ipython-input-4-5e54a5f57af4>\", line 171, in estimate_mi\n  File \"<ipython-input-4-5e54a5f57af4>\", line 21, in uf\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 243, in fit\n    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 291, in _fit\n    y = self._validate_y(y)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 651, in _validate_y\n    check_classification_targets(y)\n  File \"C:\\Users\\siptest\\anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 172, in check_classification_targets\n    raise ValueError(\"Unknown label type: %r\" % y_type)\nValueError: Unknown label type: 'continuous'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-144b08da9ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m outputs = Parallel(n_jobs=-1, verbose=100)(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimate_power\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimulations\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtests\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "outputs = Parallel(n_jobs=-1, verbose=100)(\n",
    "    [delayed(estimate_power)(sim, test) for sim in simulations for test in tests]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power():\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=5, figsize=(28,24))\n",
    "    \n",
    "    sim_title = [\n",
    "        \"Linear\",\n",
    "        \"Multiplicative\",\n",
    "        \"Independence\"\n",
    "    ]\n",
    "    \n",
    "    for i, row in enumerate(ax):\n",
    "        for j, col in enumerate(row):\n",
    "            count = 5*i + j\n",
    "            sim = simulations[count]\n",
    "            \n",
    "            for test in tests:\n",
    "                mgc_power = np.genfromtxt('C:/Users/siptest/Desktop/hyppo/benchmarks/2samp_vs_samplesize/{}_MGC.csv'.format(sim.__name__),\n",
    "                                          delimiter=',')\n",
    "                power = np.genfromtxt('C:/Users/siptest/Desktop/hyppo/benchmarks/2samp_vs_samplesize/{}_{}.csv'.format(sim.__name__, test.__name__),\n",
    "                                      delimiter=',')\n",
    "                \n",
    "                custom_color = {\n",
    "                    \"Dcorr\" : \"#377eb8\",\n",
    "                    \"Hsic\" : \"#4daf4a\",\n",
    "                    \"MGC\" : \"#e41a1c\",\n",
    "                }\n",
    "                if test.__name__ in custom_color.keys():\n",
    "                    if test.__name__ == \"UF\":\n",
    "                        col.plot(SAMP_SIZES, power - mgc_power, custom_color[test.__name__], label=test.__name__, lw=5)\n",
    "                    else:\n",
    "                        col.plot(SAMP_SIZES, power - mgc_power, custom_color[test.__name__], label=test.__name__, lw=2)\n",
    "                else:\n",
    "                    col.plot(SAMP_SIZES, power - mgc_power, label=test.__name__, lw=1)\n",
    "                col.set_xticks([])\n",
    "                if i == 3:\n",
    "                    col.set_xticks([SAMP_SIZES[0], SAMP_SIZES[-1]])\n",
    "                col.set_ylim(-1.05, 1.05)\n",
    "                col.set_yticks([])\n",
    "                if j == 0:\n",
    "                    col.set_yticks([-1, 0, 1])\n",
    "                col.set_title(sim_title[count])\n",
    "    \n",
    "    fig.text(0.5, 0.08, 'Sample Size', ha='center')\n",
    "    fig.text(0.08, 0.5, 'Statistical Power Relative to MGC', va='center', rotation='vertical')\n",
    "    leg = plt.legend(bbox_to_anchor=(0.5, 0.08), bbox_transform=plt.gcf().transFigure,\n",
    "                     ncol=5, loc='upper center')\n",
    "    leg.get_frame().set_linewidth(0.0)\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(5.0)\n",
    "    plt.subplots_adjust(hspace=.50)\n",
    "    plt.savefig('C:/Users/siptest/Desktop/hyppo/benchmarks/figs/2samp_power_sampsize.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_power()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
